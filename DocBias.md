Towards a Comparative Understanding of Bias 



Philosophical Position	1
The Quadrant of Oppositions	2
Quadrant of Oppositions Across Multiple Source and Multiple Tools	3
Conclusions	4
Bibliography	4
Annexes - MVP1	5

Philosophical Position 
In this research on the nature of bias and its detection methods, we would like to start with the definition that "bias" occurs when an action or strategic approach deviates in occurrence from the probability of being "correct" or "true" relative to Reality" However, we also acknowledge that no individual, group, or institution has perfect access to "Reality." Many approaches and beliefs are, at best, biological adaptations that may be considered "objective" within a group context but are neither universal nor more than "objective preferences," often shaped or imposed socially through various means, including coercion.
Of course, there are temporary "scientific, social, legal or political consensuses" on certain matters, as well as "technical or engineering consensuses" derived from measurements that are generally seen as "objective." Yet, interpretations of observed phenomena, validation of measurement mechanisms, and the implementation of measures to address observed biases and issues must always be subject to critical analysis rather than treated as absolute truths.
Under these conditions, from a scientific perspective, our only viable approach is to compare "biases" across sources and groups and construct pathways for communication and exposure of these biases, with the aim of fostering collaboration. We must abandon any claim to "absolute objectivity" and even denounce such claims as inherently "manipulative" in nature.
In our research, we develop methods to compare biases in data and between outputs generated by various AI systems. However, it is important to clarify the philosophical and methodological stance we adopt. This position may itself be considered a "bias"—and indeed it is. At times, adopting a stance of moral relativism is the most scientifically accurate position, but it can also be seriously harmful to those who adopt it. A well-known example of this is the "paradox of tolerance," which argues that unlimited tolerance can lead to the destruction of tolerance itself when it allows intolerant ideologies to flourish unchecked.
Certainly, industries, consultancies, and sciences—arguably, though we do not wish to ignite any "holy war"—are built on foundations that may appear fragile under this framework. Yet, these fields deliver tangible results, generate trillions in revenue, and save or improve millions of lives. The perfect can often be the enemy of the good. We acknowledge that our approach to understanding "bias" is itself "biased" in many ways. Nonetheless, we encourage our readers to adopt what is useful, enabling broader analysis of the concept while offering comparative methods and tools to measure "bias" effectively. Meanwhile, we leave the study of "bias as deviation from objective realities" to others, even if their approaches may lean toward pseudo-scientific exaggerations of scientific methods.

To highlight and visualize a pragmatic approach to bias-detection, we propose two comparative inspired visualization methods:

1. The Quadrant of Oppositions
2. The Quadrant of Oppositions Across Multiple Sources

The Quadrant of Oppositions
The foundational concept here is that at the outset of any bias analysis, researchers or individuals seeking to develop their interpretation must first define or select bias ontologies that align with their specific topic and philosophical standpoint. This initial step is critical, establishing the framework for identifying, categorizing, and analyzing biases.
Our objective is to design a user-friendly and intuitive tool to visualize biases. Therefore, we believe that one good approach for ideal visualization is to have for each bias a single corresponding counter-bias, introducing a "bias line" between two points within a two-dimensional plane. This line would intersect the origin of the axes, serving as a reference point for further analysis. Additionally, as part of the bias ontology, we propose grouping biases into quadrants or sub-quadrants. In this configuration, each bias would be located on the right side of the vertical axis (indicating positive values). At the same time, its counter-bias would be positioned on the left (indicating negative values).


	Diagram 1. Possible example of an intuitive bias visualization

The development of intuitive tools and enhanced user experience (UX) for this analysis is essential.  
This visualization would allow a document or book to be mapped according to its alignment with selected biases. If the content aligns with an individual's biases, the resulting graphical representation would tend to lean towards the right; conversely, if it opposes those biases, the depiction would shift to the left. Furthermore, the values representing biases and counter-biases could be expressed as probabilities, ranging between 0 and 1. These probabilities could then be scaled, for example, between 1 and 10, to provide a more intuitive and effective visualization.
Quadrant of Oppositions Across Multiple Source and Multiple Tools

Another method for visualizing. Comparing and ultimately detecting biases is to do it across multiple sources and tools, including outputs from different LLMs, diverse datasets, and expert evaluations. For instance, this framework could be applied to compare two versions of a training dataset, two books addressing the same topic, or two documents generated by distinct LLMs. By leveraging a visual representation where distinct colors correspond to each source or tool under analysis, we can create an intuitive and accessible means to identify patterns and divergences.
The integration of multiple LLMs into this comparative framework provides a unique opportunity to evaluate biases not only within individual models but also across systems. LLMs inherently generate probabilistic approximations, making them well-suited for assigning numerical values to observed biases. When multiple models are used, their outputs can be aggregated, averaged, or contrasted, providing a broader perspective on the biases present in the analyzed data. Additionally, discrepancies or alignments between the outputs of various LLMs may reveal systemic trends or highlight areas requiring further investigation.
However, the validity of such probabilistic categorizations, particularly along axes of positive and negative biases, remains a critical area for further exploration. The scientific reliability of these outputs must be established by comparing the estimates generated by LLMs with empirical data and expert judgments. While similarities in results across different LLMs might suggest a degree of consistency, this alignment does not inherently guarantee their scientific robustness.
To enhance reliability, the quadrant model could incorporate multiple tools and evaluation methods. For instance, combining outputs from LLMs with fairness metrics, bias audits, and domain-specific tools could provide a hybrid approach that bridges computational and expert-driven perspectives. This would allow biases to be visualized not only as isolated phenomena but as part of a multidimensional landscape shaped by the interplay of data, tools, and human interpretation.
The comparison of LLM outputs with expert evaluations is still important. Experts can provide context and insights that go beyond statistical patterns, offering a qualitative lens through which the outputs can be validated or critiqued. Conversely, LLMs can process vast datasets at scale, providing statistical baselines that might complement or challenge expert opinions. Establishing meaningful correlations between these perspectives is key to ensuring that the combined approach yields actionable and scientifically grounded insights.
Ultimately, this comparative method aims to leverage the strengths of multiple LLMs, tools, and expert analyses, acknowledging their respective limitations. By doing so, it creates a pathway toward scalable, nuanced, and collaborative bias detection, with potential applications in AI development, compliance, and ethical evaluation. However, further research is essential to refine the methodologies, assess their scalability, and ensure that they align with both scientific rigor and societal needs.
Conclusions
In conclusion, the comparative nature of bias detection reflects a recognition that absolute objectivity is an unattainable ideal, as all perspectives are shaped by biological, social, or methodological constraints. By embracing this limitation, our approach focuses on exposing, comparing, and visualizing biases across sources to foster understanding and collaboration. 
This philosophical stance acknowledges that while scientific, technical, and social obtained consensus or large majorities provide valuable insights, they are not immutable truths but should remain open to critical scrutiny. Ultimately, the goal is not to eliminate bias entirely but to create frameworks that enhance transparency and enable constructive dialogue between diverse perspectives.
Interestingly, this discussion about bias seems indirectly connected to the more heated debates during the kickoff meeting regarding methods of "regulating" and “verifying” AI systems through the "subjective" opinions of multiple experts. There appears to be a hope or belief that by selecting a sufficient number of "experts”, we might edge closer to "Reality." We extend an invitation to continue these discussions on bias and explore how “expert opinions" can contribute to bias detection or to shaping frameworks for evaluating AI systems in terms of regulations and compliance.


Bibliography
[1] Similar ideas, explained in more details and larger context: Embracing Biases with Meta-Rational Books: https://www.axiologic.net/downloads/embracing_biases.pdf 


Annexes - MVP1


# An application 

In the first step user choose: 
- A personality
- A prompt
- A long text or an AssistOS Document
- Number of top biases that must be detected
- Detects and display a list of possible biases (just running a prompt on it)
- The user can edit, remove the biases in the list  
- Press Generate and generate an AssistOS document 
- With a first chapter containing the bias diagram with biased scored 
- Chapters for each bias explaining why it scored each bias in the way it did 


Constraints: execute on server as a task, the LLM is the LLM of the personality


 
